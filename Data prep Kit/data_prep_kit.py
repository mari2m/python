# -*- coding: utf-8 -*-
"""Data prep Kit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xe2kFmUyXetm1ZQXOa6c-Ouqbs4GxiRg
"""

import pandas as pd
import numpy as np
from typing import Optional, Union
from google.colab import files

class DataPrepKit:
    """
    A helper class for preprocessing employee dataset using Pandas and NumPy.
    This class provides methods to read data, summarize it, handle missing values,
    and encode categorical variables.
    """

    def __init__(self):
        """
        Initializes the DataPrepKit class by allowing the user to upload a file.
        """
        uploaded = files.upload()
        file_path = list(uploaded.keys())[0]
        self.data = self.read_data(file_path)
    #the function read_data is expected to return a pandas.DataFrame
    #file_path: str This is a parameter type hint.It indicates that file_path should be of type string (str)

    def read_data(self, file_path: str) -> pd.DataFrame:
        """
        Reads an employee dataset from a given file path and returns a Pandas DataFrame.

        :param file_path: Path to the dataset file.
        :return: Loaded Pandas DataFrame.
        """
        if file_path.endswith(".csv"):
            return pd.read_csv(file_path)
        elif file_path.endswith(".xlsx") or file_path.endswith(".xls"):
            return pd.read_excel(file_path)
        elif file_path.endswith(".json"):
            return pd.read_json(file_path)
        else:
            raise ValueError("Unsupported file format. Please provide a CSV, Excel, or JSON file.")

    def summarize_data(self) -> pd.DataFrame:
        """
        Generates a summary of the employee dataset, including mean, median, mode, and standard deviation.

        :return: Pandas DataFrame with summary statistics.
        """
        summary = self.data.describe(include='all').transpose()
        summary['missing_values'] = self.data.isnull().sum()
        return summary

    def handle_missing_values(self) -> None:
        """
        Handles missing values by allowing user to choose a strategy.
        """
        strategy = input("Choose strategy for handling missing values (drop/mean/median/mode): ")
        column = input("Enter column name to apply strategy (leave blank for all columns): ")
        column = column if column else None

        if strategy == "drop":
            self.data.dropna(inplace=True)
        elif strategy in ["mean", "median", "mode"]:
            if column:
                if strategy == "mean":
                    self.data[column].fillna(self.data[column].mean(), inplace=True)
                elif strategy == "median":
                    self.data[column].fillna(self.data[column].median(), inplace=True)
                elif strategy == "mode":
                    self.data[column].fillna(self.data[column].mode()[0], inplace=True)
            else:
                for col in self.data.select_dtypes(include=[np.number]):
                    if strategy == "mean":
                        self.data[col].fillna(self.data[col].mean(), inplace=True)
                    elif strategy == "median":
                        self.data[col].fillna(self.data[col].median(), inplace=True)
                    elif strategy == "mode":
                        self.data[col].fillna(self.data[col].mode()[0], inplace=True)
        else:
            raise ValueError("Invalid strategy. Choose from 'drop', 'mean', 'median', or 'mode'.")

    def encode_categorical(self) -> None:
        """
        Encodes categorical features by allowing user to choose an encoding method.
        """
        method = input("Choose encoding method (onehot/label): ")
        categorical_cols = self.data.select_dtypes(include=['object']).columns

        if method == "onehot":
            self.data = pd.get_dummies(self.data, columns=categorical_cols)
        elif method == "label":
            from sklearn.preprocessing import LabelEncoder
            le = LabelEncoder()
            for col in categorical_cols:
                self.data[col] = le.fit_transform(self.data[col])
        else:
            raise ValueError("Invalid encoding method. Choose 'onehot' or 'label'.")

    def get_data(self) -> pd.DataFrame:
        """
        Returns the processed employee dataset.

        :return: Pandas DataFrame.
        """
        return self.data

    def save_data(self) -> None:
        """
        Saves the processed employee dataset based on user input.
        """
        output_path = input("Enter the output file name with extension (csv/xlsx/json): ")
        if output_path.endswith(".csv"):
            self.data.to_csv(output_path, index=False)
        elif output_path.endswith(".xlsx"):
            self.data.to_excel(output_path, index=False)
        elif output_path.endswith(".json"):
            self.data.to_json(output_path, orient='records')
        else:
            raise ValueError("Unsupported file format. Please use CSV, Excel, or JSON.")

# Example usage
if __name__ == "__main__":
    # Initialize DataPrepKit with user-uploaded file
    data_prep = DataPrepKit()

    # Print dataset summary
    print("Employee Data Summary:\n", data_prep.summarize_data())

    # Handle missing values based on user choice
    data_prep.handle_missing_values()

    # Encode categorical features based on user choice
    data_prep.encode_categorical()

    # Get and print processed data
    print("Processed Employee Data:\n", data_prep.get_data().head())

    # Save processed data based on user input
    data_prep.save_data()

